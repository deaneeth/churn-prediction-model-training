{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "550482f3",
   "metadata": {},
   "source": [
    "### 1. Importing Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23fc8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import (\n",
    "                                StratifiedKFold,\n",
    "                                cross_validate,\n",
    "                                GridSearchCV\n",
    "                                \n",
    "                                )\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc4e360",
   "metadata": {},
   "source": [
    "now we are trying to train multiple models with the base model we currently have to understand the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9c881",
   "metadata": {},
   "source": [
    "### 2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4aecc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('artifacts\\X_train.npz') ['arr_0']\n",
    "Y_train = np.load('artifacts\\Y_train.npz')  ['arr_0']\n",
    "X_test = np.load('artifacts\\X_test.npz')  ['arr_0']\n",
    "Y_test = np.load('artifacts\\Y_test.npz')  ['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d1b2f5",
   "metadata": {},
   "source": [
    "### 3. Define Multi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24ca7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the hyper parameters for these models\n",
    "# this is a model dictionary that upper created by defining the models\n",
    "\n",
    "lr_param_grid = {\n",
    "            'max_iter' : [1000, 5000, 10000]                        #logistic regression parameter grid\n",
    "                }\n",
    "\n",
    "dt_param_grid = {\n",
    "            'max_depth' : [8, 12, 16, 20],\n",
    "            'criterion' : [\"gini\", \"entropy\", \"log_loss\"]           #when depth increases model training time will be also increases ()\n",
    "                }                                                   # decision tree parameter grid\n",
    "\n",
    "rf_param_grid = {\n",
    "            'n_estimators' : [50, 100, 150, 200],                   #this means how many trees in the random forrest/random numbers we dont know how many would we need\n",
    "            'max_depth' : [8, 12, 16, 20],\n",
    "            'criterion' : [\"gini\", \"entropy\", \"log_loss\"]\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "                'Logistic Regression' : lr_param_grid,\n",
    "                'Decision Tree' : dt_param_grid,\n",
    "                'Random Forrest' : rf_param_grid,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479dc5b8",
   "metadata": {},
   "source": [
    "### 4. Define Multi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c836928",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "            'Logistic Regression' : LogisticRegression(),\n",
    "            'Decision Tree' : DecisionTreeClassifier() ,\n",
    "            'Random Forrest' : RandomForestClassifier()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de877cd",
   "metadata": {},
   "source": [
    "up there is usually works like this,\n",
    "\n",
    "ex:\n",
    "df_param_grid :\n",
    "- 8 x 'gini' | 8 x 'entropy' | 8 x 'log_loss'\n",
    "- 12 x 'gini' | 12 x 'entropy' | 12 x 'log_loss'\n",
    "- 16 x 'gini' | 16 x 'entropy' | 16 x 'log_loss'\n",
    "- 20 x 'gini' | 20 x 'entropy' | 20 x 'log_loss'\n",
    "\n",
    "this is called cross-validation\n",
    "Overall we call as 'Grid search' for this operation\n",
    "\n",
    "We are going to train,\n",
    "\n",
    "- 3 x Linear regression Models\n",
    "- 12 x Decision tree Models [max_depth : size x criterion : size]\n",
    "- 48 x Random Forrest Models [n_estimators : size x max_depth : size x criterion : size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ce0d6",
   "metadata": {},
   "source": [
    "### 4. Configure K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0477fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = cross-validation\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "                        n_splits=6,\n",
    "                        random_state=42,\n",
    "                        shuffle=True #by shuffling you make the operation more random, that means better performance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570dd4f",
   "metadata": {},
   "source": [
    "Now we are trying to do is that run the cross validation between these models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35beb377",
   "metadata": {},
   "source": [
    "### 5. Multi-Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196f2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Logistic Regression ---\n",
      "Fitting gridSearchCV for Logistic Regression\n",
      "Fitting 6 folds for each of 3 candidates, totalling 18 fits\n",
      "Logistic Regression gridSearchCV completed...\n",
      "Best parameters : {'max_iter': 1000}\n",
      "Best CV Score : 0.731872171052841\n",
      "\n",
      "--- Tuning Decision Tree ---\n",
      "Fitting gridSearchCV for Decision Tree\n",
      "Fitting 6 folds for each of 12 candidates, totalling 72 fits\n",
      "Decision Tree gridSearchCV completed...\n",
      "Best parameters : {'criterion': 'entropy', 'max_depth': 20}\n",
      "Best CV Score : 0.8352759689512504\n",
      "\n",
      "--- Tuning Random Forrest ---\n",
      "Fitting gridSearchCV for Random Forrest\n",
      "Fitting 6 folds for each of 48 candidates, totalling 288 fits\n",
      "Random Forrest gridSearchCV completed...\n",
      "Best parameters : {'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 200}\n",
      "Best CV Score : 0.8940327293097221\n"
     ]
    }
   ],
   "source": [
    "grid_search_results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Tuning {model_name} ---\")\n",
    "    \n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "                                estimator=model,\n",
    "                                param_grid=param_grid,\n",
    "                                cv=cv,\n",
    "                                scoring='f1',\n",
    "                                verbose=1,\n",
    "                                return_train_score=False\n",
    "                                )\n",
    "    \n",
    "    print(f\"Fitting gridSearchCV for {model_name}\")\n",
    "    \n",
    "    grid_search.fit(X_train, Y_train)\n",
    "    \n",
    "    grid_search_results[model_name] = grid_search\n",
    "    \n",
    "    print(f\"{model_name} gridSearchCV completed...\")\n",
    "    print(f\"Best parameters : {grid_search.best_params_}\")\n",
    "    print(f\"Best CV Score : {grid_search.best_score_}\")  # you can easily get the best parameters and CV scores by this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f8a12",
   "metadata": {},
   "source": [
    "- now we have the understanding of what are the parameteres.\n",
    "- But the main problem with grid search is that its very time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "936e02c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': GridSearchCV(cv=StratifiedKFold(n_splits=6, random_state=42, shuffle=True),\n",
       "              estimator=LogisticRegression(),\n",
       "              param_grid={'max_iter': [1000, 5000, 10000]}, scoring='f1',\n",
       "              verbose=1),\n",
       " 'Decision Tree': GridSearchCV(cv=StratifiedKFold(n_splits=6, random_state=42, shuffle=True),\n",
       "              estimator=DecisionTreeClassifier(),\n",
       "              param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                          'max_depth': [8, 12, 16, 20]},\n",
       "              scoring='f1', verbose=1),\n",
       " 'Random Forrest': GridSearchCV(cv=StratifiedKFold(n_splits=6, random_state=42, shuffle=True),\n",
       "              estimator=RandomForestClassifier(),\n",
       "              param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                          'max_depth': [8, 12, 16, 20],\n",
       "                          'n_estimators': [50, 100, 150, 200]},\n",
       "              scoring='f1', verbose=1)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
